{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating Hashed Passwords for Authentication:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Everytime when a new user is added to the app, we need to get the user_id (usually email) and their password from them.\n",
    "* Then we need to create a `Hash` of the password and add it to the `authenticator.yml` file in order for the user to be able to log-in to the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$2b$12$tdKt5p7nfhQgcDG30FldqeTZLUio5P.vAqKXSqiUHxURaei7Npkq2']\n"
     ]
    }
   ],
   "source": [
    "from streamlit_authenticator.utilities.hasher import Hasher\n",
    "\n",
    "hashed_passwords = Hasher(['abc123']).generate()\n",
    "print(hashed_passwords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$2b$12$N9w9IGLBfLv1tne8lzalUOm2hH4ytnvbTgQ.vs0jV6EbKt9x2QPr6']\n"
     ]
    }
   ],
   "source": [
    "hashed_passwords = Hasher(['blackpearl']).generate()\n",
    "print(hashed_passwords) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing the connection with Snowflake Data warehouse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = snowflake.connector.connect(\n",
    "    user='hariharan',\n",
    "    password= os.getenv('SNOWSQL_PWD'),\n",
    "    account=os.getenv('SNOWSQL_ACCOUNT'),\n",
    "    warehouse = os.getenv('SNOWSQL_WAREHOUSE'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOOD_DELIVERY\n",
      "SNOWFLAKE\n",
      "SNOWFLAKE_SAMPLE_DATA\n"
     ]
    }
   ],
   "source": [
    "# Show all the databses present in the database\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SHOW DATABASES\")\n",
    "result = cur.fetchall()\n",
    "for row in result:\n",
    "    schema_name = row[1]\n",
    "    print(schema_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORE\n",
      "INFORMATION_SCHEMA\n",
      "PUBLIC\n"
     ]
    }
   ],
   "source": [
    "# Show all the schemas present in the database\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SHOW SCHEMAS IN FOOD_DELIVERY\")\n",
    "result = cur.fetchall()\n",
    "for row in result:\n",
    "    schema_name = row[1]\n",
    "    print(schema_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MENU_ITEMS\n",
      "ORDERS\n",
      "ORDER_DETAILS\n",
      "PAYMENTS\n",
      "RESTAURANTS\n",
      "REVIEWS\n",
      "USERS\n"
     ]
    }
   ],
   "source": [
    "# Show all the tables present in the schema CORE\n",
    "cur.execute(\"SHOW TABLES IN SCHEMA FOOD_DELIVERY.CORE\")\n",
    "result = cur.fetchall()\n",
    "for row in result:\n",
    "    table_name = row[1]\n",
    "    print(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73748, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDER_ID</th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>ORDER_TIME</th>\n",
       "      <th>DELIVERY_ADDRESS</th>\n",
       "      <th>ORDER_STATUS</th>\n",
       "      <th>RESTAURANT_ID</th>\n",
       "      <th>TOTAL_AMOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>716d868b-2b5a-4bee-bc2c-ee262c81588f</td>\n",
       "      <td>d36e1a86-6e33-434a-b9c7-3f5c30753402</td>\n",
       "      <td>2024-06-01 11:53:19</td>\n",
       "      <td>9198 Gabriela Green\\nEast Marcton, DC 16873</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>R18329211</td>\n",
       "      <td>152.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0f41a3a7-954a-4e24-ad84-dba22e8dd154</td>\n",
       "      <td>1ae81af6-6b78-4695-8996-442e9e40ad3c</td>\n",
       "      <td>2024-06-01 08:11:05</td>\n",
       "      <td>366 Byrd Hills\\nNew Robert, WI 24455</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>R22670500</td>\n",
       "      <td>191.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fde175ad-d2ea-4901-a5fd-5c28f44e7382</td>\n",
       "      <td>2c1492fd-c993-4d00-9086-dc105c821bae</td>\n",
       "      <td>2024-06-01 21:46:46</td>\n",
       "      <td>71211 Gregory Track\\nGreenestad, OH 72514</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>R66375744</td>\n",
       "      <td>35.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99e370cd-f55e-4793-b0e6-0c41d8fd9287</td>\n",
       "      <td>523d1f1a-9edd-4811-9472-f65a52d51f15</td>\n",
       "      <td>2024-06-01 09:04:39</td>\n",
       "      <td>070 Steven Heights\\nRoachville, PW 12962</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>R42644875</td>\n",
       "      <td>149.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a88b8bf1-9fdf-4c8e-87ab-ac3a390d05e0</td>\n",
       "      <td>a6c31749-eb2a-40f3-aa65-49ead5cfdc3a</td>\n",
       "      <td>2024-06-01 21:05:23</td>\n",
       "      <td>9382 Alyssa Branch\\nShellyfurt, VI 11466</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>R23024716</td>\n",
       "      <td>129.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ORDER_ID                               USER_ID  \\\n",
       "0  716d868b-2b5a-4bee-bc2c-ee262c81588f  d36e1a86-6e33-434a-b9c7-3f5c30753402   \n",
       "1  0f41a3a7-954a-4e24-ad84-dba22e8dd154  1ae81af6-6b78-4695-8996-442e9e40ad3c   \n",
       "2  fde175ad-d2ea-4901-a5fd-5c28f44e7382  2c1492fd-c993-4d00-9086-dc105c821bae   \n",
       "3  99e370cd-f55e-4793-b0e6-0c41d8fd9287  523d1f1a-9edd-4811-9472-f65a52d51f15   \n",
       "4  a88b8bf1-9fdf-4c8e-87ab-ac3a390d05e0  a6c31749-eb2a-40f3-aa65-49ead5cfdc3a   \n",
       "\n",
       "           ORDER_TIME                             DELIVERY_ADDRESS  \\\n",
       "0 2024-06-01 11:53:19  9198 Gabriela Green\\nEast Marcton, DC 16873   \n",
       "1 2024-06-01 08:11:05         366 Byrd Hills\\nNew Robert, WI 24455   \n",
       "2 2024-06-01 21:46:46    71211 Gregory Track\\nGreenestad, OH 72514   \n",
       "3 2024-06-01 09:04:39     070 Steven Heights\\nRoachville, PW 12962   \n",
       "4 2024-06-01 21:05:23     9382 Alyssa Branch\\nShellyfurt, VI 11466   \n",
       "\n",
       "  ORDER_STATUS RESTAURANT_ID  TOTAL_AMOUNT  \n",
       "0    Delivered     R18329211        152.85  \n",
       "1    Delivered     R22670500        191.50  \n",
       "2    Delivered     R66375744         35.88  \n",
       "3    Delivered     R42644875        149.57  \n",
       "4    Delivered     R23024716        129.32  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating cursor object\n",
    "cur = con.cursor()\n",
    "\n",
    "# Execute a statement that will generate a result set.\n",
    "sql = \"SELECT * FROM FOOD_DELIVERY.CORE.ORDERS\"\n",
    "cur.execute(sql)\n",
    "\n",
    "# Fetch the result set from the cursor and deliver it as the pandas DataFrame.\n",
    "df = cur.fetch_pandas_all()\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing the connection with Databricks Data warehouse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "import pandas as pd \n",
    "from databricks import sql \n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a connection to databricks\n",
    "connection = sql.connect(server_hostname=os.getenv(\"DATABRICKS_SERVER_HOSTNAME\"),\n",
    "                         http_path=os.getenv(\"DATABRICKS_HTTP_PATH\"),\n",
    "                         access_token=os.getenv(\"DATABRICKS_ACCESS_TOKEN\")\n",
    "                         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_1941/705794241.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"SELECT * FROM hive_metastore.online_food_business.menu_items\", connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>menu_item_id</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R32379007_1</td>\n",
       "      <td>R32379007</td>\n",
       "      <td>Tacos</td>\n",
       "      <td>10.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R32379007_2</td>\n",
       "      <td>R32379007</td>\n",
       "      <td>Burritos</td>\n",
       "      <td>13.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R32379007_3</td>\n",
       "      <td>R32379007</td>\n",
       "      <td>Enchiladas</td>\n",
       "      <td>14.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R32379007_4</td>\n",
       "      <td>R32379007</td>\n",
       "      <td>Quesadillas</td>\n",
       "      <td>10.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R32379007_5</td>\n",
       "      <td>R32379007</td>\n",
       "      <td>Nachos</td>\n",
       "      <td>10.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  menu_item_id restaurant_id    item_name  price\n",
       "0  R32379007_1     R32379007        Tacos  10.20\n",
       "1  R32379007_2     R32379007     Burritos  13.93\n",
       "2  R32379007_3     R32379007   Enchiladas  14.15\n",
       "3  R32379007_4     R32379007  Quesadillas  10.47\n",
       "4  R32379007_5     R32379007       Nachos  10.80"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM hive_metastore.online_food_business.menu_items\", connection)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing the connection with OpenAI API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='In the realm of code where logic reigns,  \\nThere dwells a concept, where beauty gains,  \\nRecursive thoughts, like whispers in trees,  \\nUnfold their secrets, a dance on the keys.  \\n\\nImagine a puzzle, with pieces askew,  \\nTo solve it completely, what must you do?  \\nBreak it to bits, that’s the crafter’s decree,  \\nFor recursion bends time, like branches of a tree.  \\n\\nA function calls forth, a voice echoing clear,  \\n\"Look at the smaller, and hold it near!\"  \\nA task lightly born, yet endlessly spun,  \\nFor in each little call, the journey\\'s begun.  \\n\\nBase case awaits, like a lighthouse’s beam,  \\nA stopping point found, in this coding dream.  \\nWhen n equals one, or perhaps zero,  \\nThe function returns, a hero in shadow.  \\n\\nBut should there be more, the dance starts anew,  \\nThe function dives deeper, pursuing its due,  \\nWith each layered call, the stack rises high,  \\nA mountain of logic, reaching the sky.  \\n\\nYet heed well, dear coder, this tale has its cost,  \\nFor each step into depths, some CPU might be lost.  \\nIn stacks that grow tall, there’s danger to see,  \\nToo many recursions, cause system unease.  \\n\\nSo cherish the power, but wield with respect,  \\nFor recursion\\'s a treasure, not hands to neglect.  \\nLike mirrors reflecting, a fractal\\'s delight,  \\nIn each self-reference, the world takes flight.  \\n\\nSo, dance with recursion, in rhythm divine,  \\nLet functions call functions, your code intertwined.  \\nFor in every return, there’s a lesson we trace—  \\nThe beauty of cycles, where chaos meets grace.', role='assistant', function_call=None, tool_calls=None, refusal=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Retrieving the Table Schema, Categorical Column details and Sample rows for Prompt Context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "import pandas as pd \n",
    "from databricks import sql \n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected tables list \n",
    "catalog = \"hive_metastore\"\n",
    "schema = \"online_food_business\"\n",
    "tables_list = [\"menu_items\",\"orders\",\"users\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_schema = \"\"\n",
    "\n",
    "# # Iterating through each selected tables and get the list of columns for each table.\n",
    "# for table in tables_list:\n",
    "\n",
    "#     conn = sql.connect(server_hostname = os.getenv(\"DATABRICKS_SERVER_HOSTNAME\"),\n",
    "#                     http_path       = os.getenv(\"DATABRICKS_HTTP_PATH\"),\n",
    "#                     access_token    = os.getenv(\"DATABRICKS_ACCESS_TOKEN\"))        \n",
    "\n",
    "#     # Getting the Schema for the table\n",
    "#     query = f\"SHOW CREATE TABLE `{catalog}`.{schema}.{table}\"\n",
    "#     df = pd.read_sql(sql=query,con=conn)\n",
    "#     stmt = df['createtab_stmt'][0]\n",
    "#     stmt = stmt.split(\"USING\")[0]\n",
    "\n",
    "#     # Filtering the String columns from the table to identify Categorical columns\n",
    "#     query = f\"DESCRIBE TABLE `{catalog}`.{schema}.{table}\"\n",
    "#     df = pd.read_sql(sql=query,con=conn)\n",
    "#     string_cols = df[df['data_type']=='string']['col_name'].values.tolist()\n",
    "\n",
    "#     sql_distinct = \"\"\n",
    "#     for col in string_cols:\n",
    "#         # Getting the distinct values for each column as rows\n",
    "#         if col == string_cols[-1]:\n",
    "#             sql_distinct += f\"SELECT '{col}' AS column_name, COUNT(DISTINCT {col}) AS cnt, ARRAY_AGG(DISTINCT {col}) AS values FROM `{catalog}`.{schema}.{table}\"\n",
    "#         else:\n",
    "#             sql_distinct += f\"SELECT '{col}' AS column_name, COUNT(DISTINCT {col}) AS cnt, ARRAY_AGG(DISTINCT {col}) AS values FROM `{catalog}`.{schema}.{table} UNION ALL \"\n",
    "\n",
    "#     # print(sql_distinct)\n",
    "#     df_categories = pd.read_sql(sql=sql_distinct,con=conn)\n",
    "#     df_categories = df_categories[df_categories['cnt'] <= 20]\n",
    "#     df_categories = df_categories.drop(columns='cnt')\n",
    "\n",
    "#     if df_categories.empty:\n",
    "#         df_categories_string = \"No Categorical Fields\"\n",
    "#     else:\n",
    "#         df_categories_string = df_categories.to_string(index=False)\n",
    "\n",
    "\n",
    "#     # Getting the sample rows from the table\n",
    "#     query = f\"SELECT * FROM `{catalog}`.{schema}.{table} LIMIT 3\"\n",
    "#     df = pd.read_sql(sql=query,con=conn)\n",
    "#     sample_rows = df.to_string(index=False)\n",
    "\n",
    "    \n",
    "#     # df_categories = df_string.groupby('col_name').filter(lambda x: x['col_name'].count() <= 20)\n",
    "#     # print(df_string)\n",
    "#     # print(df_categories)\n",
    "#     if table_schema == \"\":\n",
    "#         table_schema = stmt + \"\\n\" + sample_rows + \"\\n\\nCategorical Fields:\\n\" + df_categories_string + \"\\n\"\n",
    "#     else:\n",
    "#         table_schema = table_schema + \"\\n\" + stmt + \"\\n\" + sample_rows + \"\\n\\nCategorical Fields:\\n\" + df_categories_string + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create enriched database schema details for the Prompt\n",
    "def get_enriched_database_schema(catalog,schema,tables_list):\n",
    "    table_schema = \"\"\n",
    "\n",
    "    # Iterating through each selected tables and get the list of columns for each table.\n",
    "    for table in tables_list:\n",
    "\n",
    "        conn = sql.connect(server_hostname = os.getenv(\"DATABRICKS_SERVER_HOSTNAME\"),\n",
    "                        http_path       = os.getenv(\"DATABRICKS_HTTP_PATH\"),\n",
    "                        access_token    = os.getenv(\"DATABRICKS_ACCESS_TOKEN\"))        \n",
    "\n",
    "        # Getting the Schema for the table\n",
    "        query = f\"SHOW CREATE TABLE `{catalog}`.{schema}.{table}\"\n",
    "        df = pd.read_sql(sql=query,con=conn)\n",
    "        stmt = df['createtab_stmt'][0]\n",
    "        stmt = stmt.split(\"USING\")[0]\n",
    "\n",
    "        # Filtering the String columns from the table to identify Categorical columns\n",
    "        query = f\"DESCRIBE TABLE `{catalog}`.{schema}.{table}\"\n",
    "        df = pd.read_sql(sql=query,con=conn)\n",
    "        string_cols = df[df['data_type']=='string']['col_name'].values.tolist()\n",
    "\n",
    "        sql_distinct = \"\"\n",
    "        for col in string_cols:\n",
    "            # Getting the distinct values for each column as rows\n",
    "            if col == string_cols[-1]:\n",
    "                sql_distinct += f\"SELECT '{col}' AS column_name, COUNT(DISTINCT {col}) AS cnt, ARRAY_AGG(DISTINCT {col}) AS values FROM `{catalog}`.{schema}.{table}\"\n",
    "            else:\n",
    "                sql_distinct += f\"SELECT '{col}' AS column_name, COUNT(DISTINCT {col}) AS cnt, ARRAY_AGG(DISTINCT {col}) AS values FROM `{catalog}`.{schema}.{table} UNION ALL \"\n",
    "\n",
    "        print(sql_distinct)\n",
    "        df_categories = pd.read_sql(sql=sql_distinct,con=conn)\n",
    "        df_categories = df_categories[df_categories['cnt'] <= 20]\n",
    "        df_categories = df_categories.drop(columns='cnt')\n",
    "        print(df_categories)\n",
    "\n",
    "        if df_categories.empty:\n",
    "            df_categories_string = \"No Categorical Fields\"\n",
    "        else:\n",
    "            df_categories_string = df_categories.to_string(index=False)\n",
    "\n",
    "\n",
    "        # Getting the sample rows from the table\n",
    "        query = f\"SELECT * FROM `{catalog}`.{schema}.{table} LIMIT 3\"\n",
    "        df = pd.read_sql(sql=query,con=conn)\n",
    "        sample_rows = df.to_string(index=False)\n",
    "\n",
    "        if table_schema == \"\":\n",
    "            table_schema = stmt + \"\\n\" + sample_rows + \"\\n\\nCategorical Fields:\\n\" + df_categories_string + \"\\n\"\n",
    "        else:\n",
    "            table_schema = table_schema + \"\\n\" + stmt + \"\\n\" + sample_rows + \"\\n\\nCategorical Fields:\\n\" + df_categories_string + \"\\n\"\n",
    "    \n",
    "    return table_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_5536/958397133.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql=query,con=conn)\n",
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_5536/958397133.py:20: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql=query,con=conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT 'menu_item_id' AS column_name, COUNT(DISTINCT menu_item_id) AS cnt, ARRAY_AGG(DISTINCT menu_item_id) AS values FROM `hive_metastore`.online_food_business.menu_items UNION ALL SELECT 'restaurant_id' AS column_name, COUNT(DISTINCT restaurant_id) AS cnt, ARRAY_AGG(DISTINCT restaurant_id) AS values FROM `hive_metastore`.online_food_business.menu_items UNION ALL SELECT 'item_name' AS column_name, COUNT(DISTINCT item_name) AS cnt, ARRAY_AGG(DISTINCT item_name) AS values FROM `hive_metastore`.online_food_business.menu_items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_5536/958397133.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_categories = pd.read_sql(sql=sql_distinct,con=conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [column_name, values]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_5536/958397133.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql=query,con=conn)\n",
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_5536/958397133.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql=query,con=conn)\n",
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_5536/958397133.py:20: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql=query,con=conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT 'order_id' AS column_name, COUNT(DISTINCT order_id) AS cnt, ARRAY_AGG(DISTINCT order_id) AS values FROM `hive_metastore`.online_food_business.orders UNION ALL SELECT 'user_id' AS column_name, COUNT(DISTINCT user_id) AS cnt, ARRAY_AGG(DISTINCT user_id) AS values FROM `hive_metastore`.online_food_business.orders UNION ALL SELECT 'delivery_address' AS column_name, COUNT(DISTINCT delivery_address) AS cnt, ARRAY_AGG(DISTINCT delivery_address) AS values FROM `hive_metastore`.online_food_business.orders UNION ALL SELECT 'order_status' AS column_name, COUNT(DISTINCT order_status) AS cnt, ARRAY_AGG(DISTINCT order_status) AS values FROM `hive_metastore`.online_food_business.orders UNION ALL SELECT 'restaurant_id' AS column_name, COUNT(DISTINCT restaurant_id) AS cnt, ARRAY_AGG(DISTINCT restaurant_id) AS values FROM `hive_metastore`.online_food_business.orders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_5536/958397133.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_categories = pd.read_sql(sql=sql_distinct,con=conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    column_name                                        values\n",
      "3  order_status  [Cancelled, Pending, Undelivered, Delivered]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_5536/958397133.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql=query,con=conn)\n",
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_5536/958397133.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql=query,con=conn)\n",
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_5536/958397133.py:20: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql=query,con=conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT 'user_id' AS column_name, COUNT(DISTINCT user_id) AS cnt, ARRAY_AGG(DISTINCT user_id) AS values FROM `hive_metastore`.online_food_business.users UNION ALL SELECT 'name' AS column_name, COUNT(DISTINCT name) AS cnt, ARRAY_AGG(DISTINCT name) AS values FROM `hive_metastore`.online_food_business.users UNION ALL SELECT 'gender' AS column_name, COUNT(DISTINCT gender) AS cnt, ARRAY_AGG(DISTINCT gender) AS values FROM `hive_metastore`.online_food_business.users UNION ALL SELECT 'email' AS column_name, COUNT(DISTINCT email) AS cnt, ARRAY_AGG(DISTINCT email) AS values FROM `hive_metastore`.online_food_business.users UNION ALL SELECT 'phone_number' AS column_name, COUNT(DISTINCT phone_number) AS cnt, ARRAY_AGG(DISTINCT phone_number) AS values FROM `hive_metastore`.online_food_business.users UNION ALL SELECT 'delivery_address' AS column_name, COUNT(DISTINCT delivery_address) AS cnt, ARRAY_AGG(DISTINCT delivery_address) AS values FROM `hive_metastore`.online_food_business.users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_5536/958397133.py:32: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_categories = pd.read_sql(sql=sql_distinct,con=conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  column_name          values\n",
      "2      gender  [Female, Male]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_5536/958397133.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql=query,con=conn)\n"
     ]
    }
   ],
   "source": [
    "table_schema = get_enriched_database_schema(catalog,schema,tables_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE hive_metastore.online_food_business.menu_items (\n",
      "  menu_item_id STRING,\n",
      "  restaurant_id STRING,\n",
      "  item_name STRING,\n",
      "  price DOUBLE)\n",
      "\n",
      "menu_item_id restaurant_id  item_name  price\n",
      " R32379007_1     R32379007      Tacos  10.20\n",
      " R32379007_2     R32379007   Burritos  13.93\n",
      " R32379007_3     R32379007 Enchiladas  14.15\n",
      "\n",
      "Categorical Fields:\n",
      "No Categorical Fields\n",
      "\n",
      "CREATE TABLE hive_metastore.online_food_business.orders (\n",
      "  order_id STRING,\n",
      "  user_id STRING,\n",
      "  order_time TIMESTAMP,\n",
      "  delivery_address STRING,\n",
      "  order_status STRING,\n",
      "  restaurant_id STRING,\n",
      "  total_amount DOUBLE)\n",
      "\n",
      "                            order_id                              user_id                order_time                            delivery_address order_status restaurant_id  total_amount\n",
      "716d868b-2b5a-4bee-bc2c-ee262c81588f d36e1a86-6e33-434a-b9c7-3f5c30753402 2024-06-01 11:53:19+00:00 9198 Gabriela Green\\nEast Marcton, DC 16873    Delivered     R18329211        152.85\n",
      "0f41a3a7-954a-4e24-ad84-dba22e8dd154 1ae81af6-6b78-4695-8996-442e9e40ad3c 2024-06-01 08:11:05+00:00        366 Byrd Hills\\nNew Robert, WI 24455    Delivered     R22670500        191.50\n",
      "fde175ad-d2ea-4901-a5fd-5c28f44e7382 2c1492fd-c993-4d00-9086-dc105c821bae 2024-06-01 21:46:46+00:00   71211 Gregory Track\\nGreenestad, OH 72514    Delivered     R66375744         35.88\n",
      "\n",
      "Categorical Fields:\n",
      " column_name                                       values\n",
      "order_status [Cancelled, Pending, Undelivered, Delivered]\n",
      "\n",
      "CREATE TABLE hive_metastore.online_food_business.users (\n",
      "  user_id STRING,\n",
      "  name STRING,\n",
      "  gender STRING,\n",
      "  email STRING,\n",
      "  phone_number STRING,\n",
      "  delivery_address STRING)\n",
      "\n",
      "                             user_id              name gender                         email        phone_number                                       delivery_address\n",
      "2c9e3b84-16d3-4f4c-858e-82dffa36f991     Daniel Molina   Male       daniel.molina@gmail.com  752.300.5266x02508 738 Carly Island Apt. 434\\nSouth Melissaberg, GU 31880\n",
      "752cffa9-d31c-45e1-b0ab-3e35567b90f4 Michael Rodriguez   Male michael.rodriguez@hotmail.com +1-776-822-7329x203      6504 Rachel Burg Apt. 042\\nCynthiaburgh, PA 66026\n",
      "bc304a8c-ad89-4757-b8c2-481c38435419     Charles Patel   Male     charles.patel@hotmail.com  774-219-6812x63426             366 Ryan Field\\nNorth Danielside, OK 02127\n",
      "\n",
      "Categorical Fields:\n",
      "column_name         values\n",
      "     gender [Female, Male]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(table_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def create_sql(question,table_schema):\n",
    "\n",
    "    ### Defining the prompt template\n",
    "    template_string = \"\"\" \n",
    "    You are a expert data engineer working with a Databricks environment.\\\n",
    "    Your task is to generate a working SQL query in Databricks SQL dialect. \\\n",
    "    During join if column name are same please use alias ex llm.customer_id \\\n",
    "    in select statement. It is also important to respect the type of columns: \\\n",
    "    if a column is string, the value should be enclosed in quotes. \\\n",
    "    If you are writing CTEs then include all the required columns. \\\n",
    "    While concatenating a non string column, make sure cast the column to string. \\\n",
    "    For date columns comparing to string , please cast the string input.\\\n",
    "    For string columns, check if it is a categorical column and only use the appropriate values provided in the schema.\\\n",
    "\n",
    "    SCHEMA:\n",
    "    ## {table_schema} ##\n",
    "\n",
    "    QUESTION:\n",
    "    ##\n",
    "    {question}\n",
    "    ##\n",
    "\n",
    "\n",
    "    IMPORTANT: MAKE SURE THE OUTPUT IS JUST THE SQL CODE AND NOTHING ELSE. Ensure the appropriate CATALOG is used in the query and SCHEMA is specified when reading the tables.\n",
    "    ##\n",
    "\n",
    "    OUTPUT:\n",
    "    \"\"\"\n",
    "    prompt_template = PromptTemplate.from_template(template_string)\n",
    "\n",
    "    ### Defining the LLM chain\n",
    "    llm_chain = LLMChain(\n",
    "        llm=ChatOpenAI(model=\"gpt-4o-mini\",temperature=0),\n",
    "        prompt=prompt_template\n",
    "    )\n",
    "\n",
    "    response =  llm_chain.invoke({\"question\":question,\"table_schema\":table_schema})\n",
    "    output = response['text']\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = create_sql(\"What is the total orders by each restaurant and total quantity?\",table_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "WITH order_summary AS (\n",
      "    SELECT \n",
      "        o.restaurant_id AS restaurant_id,\n",
      "        COUNT(o.order_id) AS total_orders,\n",
      "        SUM(o.total_amount) AS total_amount\n",
      "    FROM \n",
      "        hive_metastore.online_food_business.orders o\n",
      "    GROUP BY \n",
      "        o.restaurant_id\n",
      ")\n",
      "\n",
      "SELECT \n",
      "    os.restaurant_id AS restaurant_id,\n",
      "    os.total_orders AS total_orders,\n",
      "    os.total_amount AS total_amount\n",
      "FROM \n",
      "    order_summary os\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to render the sql code\n",
    "def process_llm_response_for_sql(response: str) -> str:\n",
    "    # Extract the Mermaid code block from the response\n",
    "    start_idx = response.find(\"```sql\") + len(\"```sql\")\n",
    "    end_idx = response.find(\"```\", start_idx)\n",
    "    sql_code = response[start_idx:end_idx].strip()\n",
    "\n",
    "    return sql_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH order_summary AS (\n",
      "    SELECT \n",
      "        o.restaurant_id AS restaurant_id,\n",
      "        COUNT(o.order_id) AS total_orders,\n",
      "        SUM(o.total_amount) AS total_amount\n",
      "    FROM \n",
      "        hive_metastore.online_food_business.orders o\n",
      "    GROUP BY \n",
      "        o.restaurant_id\n",
      ")\n",
      "\n",
      "SELECT \n",
      "    os.restaurant_id AS restaurant_id,\n",
      "    os.total_orders AS total_orders,\n",
      "    os.total_amount AS total_amount\n",
      "FROM \n",
      "    order_summary os\n"
     ]
    }
   ],
   "source": [
    "final_query_1 = process_llm_response_for_sql(result)\n",
    "print(final_query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_sql(question,sql_code,table_schema):\n",
    "\n",
    "    ### Defining the prompt template\n",
    "    template_string = \"\"\" \n",
    "    You are a expert data engineer working with a Databricks environment.\\\n",
    "    Your task is to generate a working SQL query in Databricks SQL dialect. \\\n",
    "    Enclose the complete SQL_CODE in a WITH clause and name it as MASTER. DON'T ALTER THE given SQL_CODE. \\\n",
    "    Then based on the QUESTION and the master WITH clause, generate the final SQL query based on the WITH clause.\\\n",
    "    ONLY IF additional information is needed to answer the QUESTION, then use the SCHEMA to join the details to get the final answer. \\\n",
    "\n",
    "\n",
    "    INPUT:\n",
    "    SQL_CODE:\n",
    "    ##\n",
    "    {sql_code}\n",
    "    ##\n",
    "\n",
    "    SCHEMA:\n",
    "    ## {table_schema} ##\n",
    "\n",
    "    QUESTION:\n",
    "    ##\n",
    "    {question}\n",
    "    ##\n",
    "\n",
    "    IMPORTANT: MAKE SURE THE OUTPUT IS JUST THE SQL CODE AND NOTHING ELSE.\n",
    "    ##\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \"\"\"\n",
    "    prompt_template = PromptTemplate.from_template(template_string)\n",
    "\n",
    "    ### Defining the LLM chain\n",
    "    llm_chain = LLMChain(\n",
    "        llm=ChatOpenAI(model=\"gpt-4o-mini\",temperature=0),\n",
    "        prompt=prompt_template\n",
    "    )\n",
    "\n",
    "    response =  llm_chain.invoke({\"sql_code\":sql_code,\"question\":question,\"table_schema\":table_schema})\n",
    "    output = response['text']\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_query_2 = create_advanced_sql(question=\"Can you give me the average total orders overall and also average item quantity?\",sql_code=final_query_1,table_schema=table_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH MASTER AS (\n",
      "    WITH order_summary AS (\n",
      "    SELECT \n",
      "        o.restaurant_id AS restaurant_id,\n",
      "        COUNT(o.order_id) AS total_orders,\n",
      "        SUM(o.total_amount) AS total_amount\n",
      "    FROM \n",
      "        hive_metastore.online_food_business.orders o\n",
      "    GROUP BY \n",
      "        o.restaurant_id\n",
      ")\n",
      "\n",
      "SELECT \n",
      "    os.restaurant_id AS restaurant_id,\n",
      "    os.total_orders AS total_orders,\n",
      "    os.total_amount AS total_amount\n",
      "FROM \n",
      "    order_summary os\n",
      ")\n",
      "\n",
      "SELECT \n",
      "    AVG(total_orders) AS average_total_orders,\n",
      "    AVG(total_amount / total_orders) AS average_item_quantity\n",
      "FROM \n",
      "    MASTER;\n"
     ]
    }
   ],
   "source": [
    "final_query_2 = process_llm_response_for_sql(final_query_2)\n",
    "print(final_query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\" \n",
    "\n",
    "WITH MASTER AS (\n",
    "    WITH order_summary AS (\n",
    "    SELECT \n",
    "        o.restaurant_id AS restaurant_id,\n",
    "        COUNT(o.order_id) AS total_orders,\n",
    "        SUM(o.total_amount) AS total_amount\n",
    "    FROM \n",
    "        hive_metastore.online_food_business.orders o\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    os.restaurant_id AS restaurant_id,\n",
    "    os.total_orders AS total_orders,\n",
    "    os.total_amount AS total_amount\n",
    "FROM \n",
    "    order_summary os\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    AVG(total_orders) AS average_total_orders,\n",
    "    AVG(total_amount / total_orders) AS average_item_quantity\n",
    "FROM \n",
    "    MASTER;\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Query Self-Correction Component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_query(query):\n",
    "    # Getting the sample details of the selected table\n",
    "    conn = sql.connect(server_hostname = os.getenv(\"DATABRICKS_SERVER_HOSTNAME\"),\n",
    "                    http_path       = os.getenv(\"DATABRICKS_HTTP_PATH\"),\n",
    "                    access_token    = os.getenv(\"DATABRICKS_ACCESS_TOKEN\"))\n",
    "\n",
    "    # query = query.replace(\";\",\"\")\n",
    "    # query = query + f\" LIMIT 1000;\"\n",
    "    df = pd.read_sql(sql=query,con=conn)\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_correction(query):\n",
    "    error_msg = \"\"\n",
    "\n",
    "    try:\n",
    "        df = load_data_from_query(query)\n",
    "        print(df.shape)\n",
    "        # df.head()\n",
    "        error_msg += \"Successful\"\n",
    "    except Exception as e:\n",
    "        error_msg += str(e)\n",
    "    \n",
    "    if error_msg == \"Successful\":\n",
    "        return error_msg\n",
    "    else:\n",
    "        # print(\"There is error\")\n",
    "        # print(error_msg)\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = final_query_1\n",
    "# query = \"SELECT * FROM hive_metastore.online_food_business.menu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_5536/1382692826.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql=query,con=conn)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Execution failed on sql:  \\n\\nWITH MASTER AS (\\n    WITH order_summary AS (\\n    SELECT \\n        o.restaurant_id AS restaurant_id,\\n        COUNT(o.order_id) AS total_orders,\\n        SUM(o.total_amount) AS total_amount\\n    FROM \\n        hive_metastore.online_food_business.orders o\\n)\\n\\nSELECT \\n    os.restaurant_id AS restaurant_id,\\n    os.total_orders AS total_orders,\\n    os.total_amount AS total_amount\\nFROM \\n    order_summary os\\n)\\n\\nSELECT \\n    AVG(total_orders) AS average_total_orders,\\n    AVG(total_amount / total_orders) AS average_item_quantity\\nFROM \\n    MASTER;\\n\\n\\n\\n\\n[MISSING_GROUP_BY] The query does not include a GROUP BY clause. Add GROUP BY or turn it into the window functions using OVER clauses. SQLSTATE: 42803; line 5 pos 4\\nunable to rollback'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_msg = self_correction(query)\n",
    "error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sql(question,sql_code,table_schema,error_msg):\n",
    "\n",
    "    ### Defining the prompt template\n",
    "    template_string = \"\"\" \n",
    "    You are a expert data engineer working with a Databricks environment.\\\n",
    "    Your task is to modify the SQL_CODE using Databricks SQL dialect based on the QUESTION, SCHEMA and the ERROR_MESSAGE. \\\n",
    "    If ERROR_MESSAGE is provided, then make sure to correct the SQL query according to that. \\\n",
    "\n",
    "    SCHEMA:\n",
    "    ## {table_schema} ##\n",
    "\n",
    "    ERROR_MESSAGE:\n",
    "    ## {error_msg} ##\n",
    "\n",
    "    SQL_CODE:\n",
    "    ##\n",
    "    {sql_code}\n",
    "\n",
    "    QUESTION:\n",
    "    ## {question} ##\n",
    "\n",
    "    ##\n",
    "\n",
    "\n",
    "    IMPORTANT: MAKE SURE THE OUTPUT IS JUST THE SQL CODE AND NOTHING ELSE. Ensure the appropriate CATALOG is used in the query and SCHEMA is specified when reading the tables.\n",
    "    ##\n",
    "\n",
    "    OUTPUT:\n",
    "    \"\"\"\n",
    "    prompt_template = PromptTemplate.from_template(template_string)\n",
    "\n",
    "    ### Defining the LLM chain\n",
    "    llm_chain = LLMChain(\n",
    "        llm=ChatOpenAI(model=\"gpt-4o-mini\",temperature=0),\n",
    "        prompt=prompt_template\n",
    "    )\n",
    "\n",
    "    response =  llm_chain.invoke({\"question\":question,\"sql_code\":sql_code,\"table_schema\":table_schema,\"error_msg\":error_msg})\n",
    "    output = response['text']\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n\\nWITH MASTER AS (\\n    WITH order_summary AS (\\n    SELECT \\n        o.restaurant_id AS restaurant_id,\\n        COUNT(o.order_id) AS total_orders,\\n        SUM(o.total_amount) AS total_amount\\n    FROM \\n        hive_metastore.online_food_business.orders o\\n)\\n\\nSELECT \\n    os.restaurant_id AS restaurant_id,\\n    os.total_orders AS total_orders,\\n    os.total_amount AS total_amount\\nFROM \\n    order_summary os\\n)\\n\\nSELECT \\n    AVG(total_orders) AS average_total_orders,\\n    AVG(total_amount / total_orders) AS average_item_quantity\\nFROM \\n    MASTER;\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified = correct_sql(\"Can you give me the average total orders overall and also average item quantity?\",query,table_schema,error_msg=error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "WITH MASTER AS (\n",
      "    WITH order_summary AS (\n",
      "    SELECT \n",
      "        o.restaurant_id AS restaurant_id,\n",
      "        COUNT(o.order_id) AS total_orders,\n",
      "        SUM(o.total_amount) AS total_amount\n",
      "    FROM \n",
      "        hive_metastore.online_food_business.orders o\n",
      "    GROUP BY \n",
      "        o.restaurant_id\n",
      ")\n",
      "\n",
      "SELECT \n",
      "    os.restaurant_id AS restaurant_id,\n",
      "    os.total_orders AS total_orders,\n",
      "    os.total_amount AS total_amount\n",
      "FROM \n",
      "    order_summary os\n",
      ")\n",
      "\n",
      "SELECT \n",
      "    AVG(total_orders) AS average_total_orders,\n",
      "    AVG(total_amount / total_orders) AS average_item_quantity\n",
      "FROM \n",
      "    MASTER;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_5536/1382692826.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql=query,con=conn)\n"
     ]
    }
   ],
   "source": [
    "# Final\n",
    "error_msg = self_correction(query)\n",
    "\n",
    "if error_msg == \"Successful\":\n",
    "    print(\"Query is successful\")\n",
    "else:\n",
    "    modified_query = correct_sql(\"List the details of the menu item table\",query,table_schema,error_msg=error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final function to validate and self-correct\n",
    "def validate_and_correct_sql(query,table_schema):\n",
    "    error_msg = self_correction(query)\n",
    "\n",
    "    if error_msg == \"Successful\":\n",
    "        # print(\"Query is successful\")\n",
    "        return \"Correct\",query\n",
    "    else:\n",
    "        modified_query = correct_sql(\"List the details of the menu item table\",query,table_schema,error_msg=error_msg)\n",
    "        return \"Incorrect\",modified_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT * FROM hive_metastore.online_food_business.menu_items\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(modified_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Adding Favourites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_query(query):\n",
    "    # Getting the sample details of the selected table\n",
    "    conn = sql.connect(server_hostname = os.getenv(\"DATABRICKS_SERVER_HOSTNAME\"),\n",
    "                    http_path       = os.getenv(\"DATABRICKS_HTTP_PATH\"),\n",
    "                    access_token    = os.getenv(\"DATABRICKS_ACCESS_TOKEN\"))\n",
    "\n",
    "    # query = query.replace(\";\",\"\")\n",
    "    # query = query + f\" LIMIT 1000;\"\n",
    "    df = pd.read_sql(sql=query,con=conn)\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_user_history(user_name,question,query,favourite_ind):\n",
    "    conn = sql.connect(server_hostname = os.getenv(\"DATABRICKS_SERVER_HOSTNAME\"),\n",
    "                    http_path       = os.getenv(\"DATABRICKS_HTTP_PATH\"),\n",
    "                    access_token    = os.getenv(\"DATABRICKS_ACCESS_TOKEN\"))\n",
    "    \n",
    "    user_history_table = \"hive_metastore.dev_tools.sqlgenpro_user_query_history\"\n",
    "\n",
    "    query = f\"INSERT INTO {user_history_table} VALUES ('{user_name}',current_timestamp(),'{question}','{query}',{favourite_ind})\"\n",
    "    # query = f\"SELECT * FROM {user_history_table}\"\n",
    "    df = pd.read_sql(sql=query,con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/7x619qt169344pmm32qd8wgc0000gq/T/ipykernel_19961/3664673451.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(sql=query,con=conn)\n"
     ]
    }
   ],
   "source": [
    "add_to_user_history(\"hariharan\",\"List the details of the menu item table\",query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Deploying Streamlit App:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-1\n",
    "# Logging into the EC2 Instance\n",
    "\n",
    "#----> ssh -i \"SQLGenPro.pem\" ubuntu@ec2-13-51-170-253.eu-north-1.compute.amazonaws.com\n",
    "\n",
    "# Get Root user access\n",
    "#----> sudo -i\n",
    "\n",
    "# Go to the home directory\n",
    "#----> cd /home/ubuntu\n",
    "\n",
    "# Update the packages\n",
    "#----> sudo apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-2\n",
    "# Move the app to the EC2 instance\n",
    "# NOTE: Make sure you are outside the app directory before running the following command and also the pem file is present in the same directory.\n",
    "\n",
    "#----> pip list --format=freeze > requirements.txt\n",
    "#----> scp -i SQLGenPro.pem -r SQLGenPro ubuntu@ec2-51-20-34-113.eu-north-1.compute.amazonaws.com:/home/ubuntu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-3\n",
    "# Go to the EC2 instance and check if the app folder is present in the home directory\n",
    "# Then create a python virtual environment and install the required packages\n",
    "\n",
    "#----> apt install python3.10-venv\n",
    "#----> python3 -m venv myenv\n",
    "#----> source myenv/bin/activate\n",
    "#----> pip install -r requirements.txt (after moving to the app directory)\n",
    "#----> streamlit hello \n",
    "\n",
    "#Permanent running\n",
    "#----> nohup python3 -m streamlit run SQLGenPro_Live.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqlgenpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
